{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63190ac-ba40-4229-9fe5-50635fa8705e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "from copy import deepcopy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f6e32d-52a3-44ef-9744-0fd5381dec1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DATA_DIR = 'stock_data'\n",
    "NATION = 'kr' # 'kr', 'us'\n",
    "MARKET = 'kosdaq' # 'kospi', 'kosdaq', 'nasdaq', 'nyse'\n",
    "DATA_DIR = f'{BASE_DATA_DIR}/refined_data/{NATION}/{MARKET}/*.csv'\n",
    "SECTOR_DIR = f'{BASE_DATA_DIR}/{NATION}/{MARKET}/modified_{MARKET}_top500_sector_mcap.csv'\n",
    "SEED=42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b96f4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_list = sorted(glob(DATA_DIR))\n",
    "items = []\n",
    "for idx, item_dir in enumerate(tqdm(item_list)):\n",
    "    item = pd.read_csv(item_dir)\n",
    "    item = item[item['Date'] > \"2022-12-31\"]\n",
    "    items.append(item.values)\n",
    "    \n",
    "items = np.array(items)\n",
    "date_list = items[0, :, 0]\n",
    "values = items[:, :, 1:].astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5f6351-cc75-47b6-928b-82efe324aa2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StockTradingEnv:\n",
    "    def __init__(self, data, initial_investment=10000000):\n",
    "        self.stock_price_history = data  # shape: (n_step, n_stock)\n",
    "        self.n_stock, self.n_step, self.n_feature = self.stock_price_history.shape\n",
    "        self.window_size = 10\n",
    "        self.initial_investment = initial_investment\n",
    "\n",
    "        self.current_step = None\n",
    "        self.stock_owned = None\n",
    "        self.cash_in_hand = None\n",
    "\n",
    "        self.state_dim = (\n",
    "            self.n_stock * self.window_size * self.n_feature + 1 + self.n_stock\n",
    "        )\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.current_step = 0\n",
    "        self.stock_owned = np.zeros(self.n_stock)\n",
    "        self.cash_in_hand = self.initial_investment\n",
    "        self.stock_price = self.stock_price_history[\n",
    "            :, self.current_step : self.current_step + self.window_size, 3\n",
    "        ]\n",
    "        self.stock_state = self.stock_price_history[\n",
    "            :, self.current_step : self.current_step + self.window_size, :\n",
    "        ]\n",
    "        return self._get_obs()\n",
    "\n",
    "    def step(self, action, amount):\n",
    "        prev_total_value = self._get_total_value()\n",
    "\n",
    "        self.current_step += 1\n",
    "        if self.current_step + self.window_size > self.n_step:\n",
    "            done = True\n",
    "            self.stock_price = self.stock_price_history[\n",
    "                :, -self.window_size :, 3\n",
    "            ]  # Handle edge case\n",
    "            self.stock_state = self.stock_price_history[:, -self.window_size :, :]\n",
    "        else:\n",
    "            self.stock_price = self.stock_price_history[\n",
    "                :, self.current_step : self.current_step + self.window_size, 3\n",
    "            ]\n",
    "            self.stock_state = self.stock_price_history[\n",
    "                :, self.current_step : self.current_step + self.window_size, :\n",
    "            ]\n",
    "            done = False\n",
    "\n",
    "        self._trade(action, amount)\n",
    "        current_total_value = self._get_total_value()\n",
    "\n",
    "        reward = current_total_value - prev_total_value\n",
    "        info = {\"current_total_value\": current_total_value}\n",
    "        return self._get_obs(), reward, done, info\n",
    "\n",
    "    def _get_obs(self):\n",
    "        obs = dict()\n",
    "        obs[\"state\"] = self.stock_state\n",
    "        obs[\"owned\"] = self.stock_owned\n",
    "        obs[\"cash\"] = self.cash_in_hand\n",
    "        return obs\n",
    "\n",
    "    def _get_total_value(self):\n",
    "        return self.stock_owned.dot(self.stock_price[:, -1]) + self.cash_in_hand\n",
    "\n",
    "    def _trade(self, action, amount):\n",
    "        # 행동 해석 및 거래 실행\n",
    "        if self.cash_in_hand <= 0:\n",
    "            pass\n",
    "        else:\n",
    "            for i, (action_type, num_stock) in enumerate(zip(action, amount)):\n",
    "                if action_type == 0:  # 매도\n",
    "                    if self.stock_owned[i] >= num_stock and num_stock > 0:\n",
    "                        self.stock_owned[i] -= num_stock\n",
    "                        self.cash_in_hand += self.stock_price[i, -1] * num_stock\n",
    "\n",
    "            for i, (action_type, num_stock) in enumerate(zip(action, amount)):\n",
    "                if action_type == 2:  # 매수\n",
    "                    total_cost = self.stock_price[i, -1] * num_stock\n",
    "                    if (\n",
    "                        self.cash_in_hand >= total_cost\n",
    "                        and num_stock > 0\n",
    "                        and total_cost > 0\n",
    "                    ):\n",
    "                        self.stock_owned[i] += num_stock\n",
    "                        self.cash_in_hand -= total_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68c431b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.models.dqn import DQN\n",
    "\n",
    "policy_net = DQN(state=500 * 10 * 5, n_actions=500)\n",
    "checkpoint = torch.load('./lightning_logs/version_52/checkpoints/epoch=2454-step=27005.ckpt')\n",
    "\n",
    "state_dict = checkpoint['state_dict']\n",
    "\n",
    "for k, v in list(state_dict.items()):\n",
    "    if k.startswith('policy_net.'):\n",
    "        state_dict[k[11:]] = v\n",
    "        \n",
    "    del state_dict[k]\n",
    "\n",
    "policy_net.load_state_dict(state_dict, strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063789c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_action(model, state):\n",
    "    state = torch.tensor(state['state'].astype(np.float32))\n",
    "    action, amount = model(state)\n",
    "    return action.detach().numpy(), amount.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cff316b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# 초기 투자 자본 설정\n",
    "bugget = 1e7\n",
    "# 주가 데이터(values)와 초기 투자 금액(bugget) 전달\n",
    "env = StockTradingEnv(data=values, initial_investment=bugget)\n",
    "# 시뮬레이견 환경 초기화\n",
    "state = env.reset()\n",
    "\n",
    "# 수집할 데이터를 저장할(결과 기록을 위한) 리스트\n",
    "reward_list = [] # 각 단계에서 보상 저장\n",
    "asset_list = [] # 각 단계에서의 총 자산 가치 저장\n",
    "owned_list = [] # 각 단계에서 보유한 주식 수량 저장\n",
    "action_list = [] # 각 단계에서 취한 행동 저장\n",
    "cash_in_hand_list = [] # 각 단계에서 보유한 현금의 양 저장\n",
    "\n",
    "\n",
    "# 매수할 금액 할당 함수 정의 - 주식의 매수량 계산. (softmax 함수 사용.)\n",
    "def softmax_allocation(amounts, cash_available, prices):\n",
    "    valid_mask = prices > 0  # 가격이 0보다 큰 주식만 필터링하여 선택\n",
    "    valid_amounts = amounts[valid_mask] # 필터링된 주식에 대한 매수량\n",
    "    valid_prices = prices[valid_mask] # 필터링된 주식에 대한 가격\n",
    "    # softmax 함수를 적용하여 얻은 비율을 통해 계산된 금액입니다.\n",
    "    scaled_amounts = F.softmax(torch.tensor(valid_amounts), dim=0) # softmax로 비율 계산\n",
    "    scaled_amounts = (scaled_amounts / scaled_amounts.sum()) * cash_available # softmax 비율을 총 금액에 맞게 조정\n",
    "    # buy_amounts는 계산된 매수량을 저장하는 배열.\n",
    "    buy_amounts = np.zeros_like(prices) # 모든 주식에 대한 매수량 배열 초기화\n",
    "    buy_amounts[valid_mask] = np.floor(scaled_amounts.numpy() / valid_prices).astype(int) # 매수량 계산\n",
    "    return buy_amounts\n",
    "\n",
    "# 모델에서 행동과 amount 예측\n",
    "while True:\n",
    "    # select_action 함수를 호출해서 현재 상태(state)에 대한 행동(action)과 매수/매도량(amount) 결정.\n",
    "    # action : 모델이 예측한 주식별 행동 0(매도), 1(보유), 2(매수)\n",
    "    # amount : 모델이 예측한 주식별 매수/매도량\n",
    "    action, amount = select_action(policy_net, state)\n",
    "\n",
    "    action = action.reshape(1, 500, 3).argmax(2)[0]\n",
    "    amount = amount[0]\n",
    "    \n",
    "    # amount 값 처리\n",
    "    current_prices = env.stock_price[:, -1]  # 현재 주식 가격\n",
    "    if action.sum() > 0:  # 매수나 매도 행동이 있을 경우만 처리\n",
    "        buy_mask = action == 2\n",
    "        sell_mask = action == 0\n",
    "        stay_mask = action == 1\n",
    "\n",
    "        # 매수일 경우 softmax로 금액 할당\n",
    "        buy_amounts = softmax_allocation(amount[buy_mask], env.cash_in_hand, current_prices[buy_mask])\n",
    "        \n",
    "        # 매도일 경우 최대 보유 주식량을 넘지 않게 조정\n",
    "        sell_amounts = np.minimum(env.stock_owned[sell_mask], amount[sell_mask].astype(int))\n",
    "        \n",
    "        # amount 배열 재구성\n",
    "        amount = np.zeros_like(action)\n",
    "        amount[buy_mask] = buy_amounts\n",
    "        amount[sell_mask] = sell_amounts\n",
    "        amount[stay_mask] = 0  # stay의 경우 amount는 0\n",
    "\n",
    "    else:\n",
    "        amount = np.zeros_like(action)  # 모든 행동이 stay인 경우\n",
    "    \n",
    "    # 환경에 step 실행\n",
    "    state, reward, done, info = env.step(action, amount)\n",
    "    # 결과 기록\n",
    "    owned_list.append(deepcopy(env.stock_owned))\n",
    "    action_list.append(action)\n",
    "    reward_list.append(reward)\n",
    "    asset_list.append(info['current_total_value'])\n",
    "    cash_in_hand_list.append(state['cash'])\n",
    "\n",
    "    if done:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "babde563-ad76-44b8-8deb-d01a2ef1e61a",
   "metadata": {},
   "outputs": [],
   "source": [
    "info['current_total_value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "babde563-ad76-44b8-8deb-d01a2ef1e61a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(30, 10))\n",
    "plt.plot(asset_list, label='asset')\n",
    "plt.plot(reward_list, label='reward')\n",
    "plt.plot(cash_in_hand_list, label='cash_in_hand')\n",
    "tick_positions = np.arange(0, items.shape[1], 365)\n",
    "tick_labels = np.array(date_list)[tick_positions]\n",
    "plt.xticks(tick_positions, tick_labels, rotation=45)\n",
    "plt.axhline(bugget, color='red')\n",
    "plt.title(f\"{NATION}_{MARKET}\", fontsize=20)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
